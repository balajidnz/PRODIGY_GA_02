{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CNOOKEjkT3pG"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "%cd /content\n",
        "!git clone https://github.com/rocketpal/InvokeAI\n",
        "!pip install -q dependency_injector diffusers einops eventlet facexlib flask_cors flask_socketio flaskwebgui getpass_asterisk huggingface-hub\n",
        "!pip install -q kornia omegaconf pudb pyreadline3 pytorch-lightning realesrgan streamlit taming-transformers-rom1504 test-tube torch-fidelity\n",
        "!pip install -q torchmetrics transformers picklescan\n",
        "!pip install -q pillow xformers==0.0.22 triton==2.0.0 -U\n",
        "clear_output()\n",
        "\n",
        "!pip install -q git+https://github.com/invoke-ai/GFPGAN@basicsr-1.4.2#egg=gfpgan\n",
        "!pip install -q git+https://github.com/openai/CLIP.git@main#egg=clip\n",
        "!pip install -q git+https://github.com/Birch-san/k-diffusion.git@mps#egg=k-diffusion\n",
        "!pip install -q git+https://github.com/invoke-ai/clipseg.git@relaxed-python-requirement#egg=clipseg\n",
        "!pip install -q git+https://github.com/invoke-ai/PyPatchMatch@0.1.4#egg=pypatchmatch\n",
        "%cd /content/InvokeAI/\n",
        "!pip install -q -e .\n",
        "clear_output()\n",
        "\n",
        "\n",
        "!wget https://raw.githubusercontent.com/rocketpal/InvokeAI-colab/main/INITIAL_MODELS.yaml -O /content/InvokeAI/invokeai/configs/INITIAL_MODELS.yaml\n",
        "clear_output()\n",
        "\n",
        "print('\u001b[1;32mDone!')\n",
        "\n",
        "!pip install python-socketio==5.9.0\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "%cd /content/InvokeAI/\n",
        "!python /content/InvokeAI/scripts/invokeai-model-install.py --root_dir /content/db --yes\n",
        "\n",
        "clear_output()\n",
        "print('\u001b[1;32mDone! All models downloaded successfully ðŸ™ƒ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-DjVAoBWBM1",
        "outputId": "14421d51-b15d-47a5-864b-f5dff12d30b9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mDone! All models downloaded successfully ðŸ™ƒ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shlex\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "from typing import Union\n",
        "clear_output()\n",
        "\n",
        "\n",
        "id_rsa_file = \"/content/InvokeAI/id_rsa\"\n",
        "id_rsa_pub_file = \"/content/InvokeAI/id_rsa.pub\"\n",
        "if os.path.exists(id_rsa_file):\n",
        "    os.remove(id_rsa_file)\n",
        "if os.path.exists(id_rsa_pub_file):\n",
        "    os.remove(id_rsa_pub_file)\n",
        "clear_output()\n",
        "\n",
        "def gen_key(path: Union[str, Path]) -> None:\n",
        "    path = Path(path)\n",
        "    arg_string = f'ssh-keygen -t rsa -b 4096 -N \"\" -q -f {path.as_posix()}'\n",
        "    args = shlex.split(arg_string)\n",
        "    subprocess.run(args, check=True)\n",
        "    path.chmod(0o600)\n",
        "\n",
        "ssh_name = \"id_rsa\"\n",
        "ssh_path = Path(os.path.dirname(os.getcwd())) / ssh_name\n",
        "gen_key(ssh_path)\n",
        "clear_output()\n",
        "\n",
        "import threading\n",
        "def tunnel():\n",
        "  !ssh -R 80:127.0.0.1:9090 -o StrictHostKeyChecking=no -i /content/id_rsa remote.moe\n",
        "threading.Thread(target=tunnel, daemon=True).start()\n",
        "\n",
        "%cd /content/InvokeAI/\n",
        "!python /content/InvokeAI/scripts/invokeai-web.py --root /content/db"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6V8oygSWMTl",
        "outputId": "ba901fff-4272-4d7f-da2b-1ec73b2e7f59"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/InvokeAI\n",
            "Warning: Permanently added 'remote.moe' (ED25519) to the list of known hosts.\n",
            "Hello!\n",
            "remote.moe (the service) is closed down until a viable authentication scheme is implemented\n",
            "\n",
            "https://github.com/fasmide/remotemoe/discussions/14\n",
            "Connection to remote.moe closed by remote host.\n",
            "Connection to remote.moe closed.\n",
            "2024-09-05 18:01:15.159976: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-09-05 18:01:15.179980: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-09-05 18:01:15.185997: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-09-05 18:01:16.350404: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/InvokeAI/scripts/invokeai-web.py\", line 21, in <module>\n",
            "    main()\n",
            "  File \"/content/InvokeAI/scripts/invokeai-web.py\", line 15, in main\n",
            "    from invokeai.app.api_app import invoke_api\n",
            "  File \"/content/InvokeAI/invokeai/app/api_app.py\", line 19, in <module>\n",
            "    from ..backend.util.logging import InvokeAILogger\n",
            "  File \"/content/InvokeAI/invokeai/backend/__init__.py\", line 4, in <module>\n",
            "    from .model_management import ModelManager, ModelCache, BaseModelType, ModelType, SubModelType, ModelInfo  # noqa: F401\n",
            "  File \"/content/InvokeAI/invokeai/backend/model_management/__init__.py\", line 4, in <module>\n",
            "    from .model_manager import ModelManager, ModelInfo, AddModelResult, SchedulerPredictionType  # noqa: F401\n",
            "  File \"/content/InvokeAI/invokeai/backend/model_management/model_manager.py\", line 249, in <module>\n",
            "    from .model_cache import ModelCache, ModelLocker\n",
            "  File \"/content/InvokeAI/invokeai/backend/model_management/model_cache.py\", line 31, in <module>\n",
            "    from .models import BaseModelType, ModelType, SubModelType, ModelBase\n",
            "  File \"/content/InvokeAI/invokeai/backend/model_management/models/__init__.py\", line 5, in <module>\n",
            "    from .base import (  # noqa: F401\n",
            "  File \"/content/InvokeAI/invokeai/backend/model_management/models/base.py\", line 17, in <module>\n",
            "    from diffusers import DiffusionPipeline, ConfigMixin\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/diffusers/__init__.py\", line 30, in <module>\n",
            "    from .pipelines import OnnxRuntimeModel\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/diffusers/pipelines/__init__.py\", line 19, in <module>\n",
            "    from .auto_pipeline import AutoPipelineForImage2Image, AutoPipelineForInpainting, AutoPipelineForText2Image\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/diffusers/pipelines/auto_pipeline.py\", line 20, in <module>\n",
            "    from .controlnet import (\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/diffusers/pipelines/controlnet/__init__.py\", line 15, in <module>\n",
            "    from .multicontrolnet import MultiControlNetModel\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/diffusers/pipelines/controlnet/multicontrolnet.py\", line 7, in <module>\n",
            "    from ...models.controlnet import ControlNetModel, ControlNetOutput\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/diffusers/models/__init__.py\", line 36, in <module>\n",
            "    from .controlnet_flax import FlaxControlNetModel\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/diffusers/models/controlnet_flax.py\", line 25, in <module>\n",
            "    from .modeling_flax_utils import FlaxModelMixin\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/diffusers/models/modeling_flax_utils.py\", line 46, in <module>\n",
            "    class FlaxModelMixin(PushToHubMixin):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/diffusers/models/modeling_flax_utils.py\", line 195, in FlaxModelMixin\n",
            "    def init_weights(self, rng: jax.random.KeyArray) -> Dict:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/jax/_src/deprecations.py\", line 54, in getattr\n",
            "    raise AttributeError(f\"module {module!r} has no attribute {name!r}\")\n",
            "AttributeError: module 'jax.random' has no attribute 'KeyArray'\n"
          ]
        }
      ]
    }
  ]
}